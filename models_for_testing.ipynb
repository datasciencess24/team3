{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba9bfaec-4909-4ac2-89de-65b0e15b3f43",
   "metadata": {},
   "source": [
    "# Unedited Code for Models\n",
    "\n",
    "This file contains preliminary code for the following models:\n",
    "\n",
    "1) Decision tree\n",
    "2) CNN with heatmap\n",
    "3) CNN with DT (parallel fusion architecture requiring different inputs for each model)\n",
    "4) Logistic regression\n",
    "\n",
    "These models will need to be trained on the data and their performance (precision, recall, f-score) measured against our main model, the sequential CNN-DT model (one input, passed through the CNN then to the DT). The code here is yet to be evaluated and may require major modifications for it to work.\n",
    "\n",
    "All models are meant to predict two variables - process (values 'dressing' and 'grinding') and condition ('anomalous' and 'normal')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680766cc-7744-48a8-83a6-0ed04e9f44fd",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "**Input:** Four features extracted from recordings - variance of acoustic emissions, energy of acoustic emissions, variance of current, energy of current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645a40e-4709-4206-b425-538b9b59ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To modify the given decision tree code to take as input a list of tuples with four\n",
    "elements each and return predictions for two features, namely condition (values 'anomalous'/'normal')\n",
    "and process ('dressing'/'grinding'), we need to adjust the input data handling and model training to\n",
    "accommodate multi-output classification. Here's how you can do it:\n",
    "\n",
    "Adjust Input Data Handling: Ensure the input data is structured correctly for multi-output classification.\n",
    "The input data should contain features X and a tuple of labels y where y contains two arrays: one for\n",
    "condition and one for process.\n",
    "\n",
    "Modify Model Training: Use a single DecisionTreeClassifier with the capability to handle multi-output\n",
    "classification directly or train two separate models for each output.\n",
    "\n",
    "Update Prediction and Evaluation: Adjust the prediction and evaluation to handle two outputs.\n",
    "\n",
    "Here's the modified code:\n",
    "'''\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "def TimeSeriesDT(data, args):\n",
    "    X = np.array([list(tup) for tup in data[0]])  # Convert list of tuples to array\n",
    "    y_condition = np.array([label[0] for label in data[1]])  # Extract condition labels\n",
    "    y_process = np.array([label[1] for label in data[1]])  # Extract process labels\n",
    "    y = np.vstack((y_condition, y_process)).T  # Stack condition and process labels for multi-output\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=args.split, random_state=42)\n",
    "\n",
    "    # Train model\n",
    "    DF = DecisionTreeClassifier(random_state=42)  # gini by default\n",
    "    DF.fit(X_train, y_train)\n",
    "    y_pred = DF.predict(X_test)\n",
    "\n",
    "    # Evaluate model\n",
    "    accuracy_condition = accuracy_score(y_test[:, 0], y_pred[:, 0])\n",
    "    accuracy_process = accuracy_score(y_test[:, 1], y_pred[:, 1])\n",
    "    print(f\"Accuracy Condition: {accuracy_condition}\")\n",
    "    print(f\"Accuracy Process: {accuracy_process}\")\n",
    "\n",
    "    # Compute metrics for both outputs\n",
    "    metrics_condition = compute_metrics(y_pred[:, 0], y_test[:, 0])\n",
    "    metrics_process = compute_metrics(y_pred[:, 1], y_test[:, 1])\n",
    "    print(\"Metrics for Condition:\", metrics_condition)\n",
    "    print(\"Metrics for Process:\", metrics_process)\n",
    "\n",
    "def acc_and_f1(preds, labels):\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    pre = precision_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    recall = recall_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    return {\n",
    "        \"f1\": f1,\n",
    "        \"precision\": pre,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    return acc_and_f1(preds, labels)\n",
    "\n",
    "'''\n",
    "This code assumes data[0] is a list of tuples representing the features and\n",
    "data[1] is a list of tuples where each tuple contains two elements: the condition\n",
    "label and the process label for each sample. The DecisionTreeClassifier is used\n",
    "for multi-output classification by fitting and predicting on y, which is structured\n",
    "as an array of shape (n_samples, 2), where the first column contains the condition\n",
    "labels and the second column contains the process labels. The metrics are computed\n",
    "separately for each output to evaluate the model's performance on predicting both\n",
    "condition and process.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ae973-2809-438f-9950-6502258ea86f",
   "metadata": {},
   "source": [
    "### CNN with Heatmap\n",
    "\n",
    "The first CNN uses a Grad-CAM heatmap. the second a simpler alternative. If time permits, Grad-CAM would be the preferred variant.\n",
    "\n",
    "**Input:** Wavelet transformed data not subjected to manual feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd869e-c383-48c6-87b5-840f49eeb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To add a heatmap feature for visualizing the parameters that have the strongest bearing on the\n",
    "CNN's classification decisions, you can use the Gradient-weighted Class Activation Mapping (Grad-CAM) technique.\n",
    "Grad-CAM uses the gradients of any target concept (say, the output of the model for a particular class) flowing\n",
    "into the final convolutional layer to produce a coarse localization map highlighting the important regions in\n",
    "the image for predicting the concept.\n",
    "\n",
    "However, since your model is for time series data and not images,\n",
    "the visualization will highlight important time steps instead of spatial regions.\n",
    "The implementation steps are as follows:\n",
    "\n",
    "Modify the Model: Add hooks to capture the gradients and the activations of the last convolutional layer.\n",
    "Grad-CAM Algorithm: Implement the Grad-CAM algorithm to use these gradients and activations to generate the heatmap.\n",
    "Visualization: Plot the heatmap along with the original time series data.\n",
    "Here's how you can modify your TimeSeriesCNN class and add a Grad-CAM visualization:\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TimeSeriesCNN(nn.Module):\n",
    "    def __init__(self, args, device, sequence_length):\n",
    "        super(TimeSeriesCNN, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        self.sequence_length = sequence_length\n",
    "        self._build_model()\n",
    "        self.gradients = None\n",
    "\n",
    "    def _build_model(self):\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=5, out_channels=256, kernel_size=32),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=8)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=256, out_channels=64, kernel_size=4),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=int((self.sequence_length - 32)/8 - 4 + 1))\n",
    "        )\n",
    "        # Register hook\n",
    "        self.conv2.register_backward_hook(self.save_gradients)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        self.output_feature = x\n",
    "        x = x.view(-1, 64)  # Flatten the tensor\n",
    "        x = self.mlp(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def save_gradients(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "\n",
    "    def get_activations(self, x):\n",
    "        return self.output_feature\n",
    "\n",
    "def generate_heatmap(weighted_activations):\n",
    "    # Generate the heatmap\n",
    "    heatmap = torch.mean(weighted_activations, dim=1).squeeze()\n",
    "    heatmap = np.maximum(heatmap.cpu().detach().numpy(), 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "def visualize_heatmap(original_time_series, heatmap):\n",
    "    plt.matshow([heatmap], cmap='jet', aspect='auto')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    # Overlay the heatmap on the original time series\n",
    "    # Assuming original_time_series is a 2D array of shape (time_steps, features)\n",
    "    # For simplicity, let's plot the heatmap against the first feature\n",
    "    plt.plot(original_time_series[:, 0])\n",
    "    plt.imshow(np.array([heatmap for _ in range(original_time_series.shape[1])]).T, cmap='jet', aspect='auto', alpha=0.5)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "'''\n",
    "Note: This implementation assumes you have a single output feature map from the last convolutional layer (self.conv2).\n",
    "The generate_heatmap function computes the mean of the gradients-weighted activations across the channels to produce\n",
    "a 1D heatmap for time series data. The visualize_heatmap function is a simple visualization of the heatmap.\n",
    "You might need to adjust the visualization part based on the specific structure of your time series data.\n",
    "\n",
    "To use Grad-CAM, you would:\n",
    "\n",
    "Perform a forward pass with the input data.\n",
    "Perform a backward pass with the gradients from the target class.\n",
    "Capture the output feature maps and gradients.\n",
    "Compute the weighted activations to generate the heatmap.\n",
    "Visualize the heatmap along with the original time series data.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63d53b-40a6-4ac3-84ee-d625cf9ec08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For a simpler approach to visualize the influence of different time steps on the model's predictions without\n",
    "implementing Grad-CAM, you can use the activations directly from the last convolutional layer. This method\n",
    "won't provide as precise insights as Grad-CAM but can still offer useful visualizations to understand which\n",
    "parts of the input time series the model is focusing on.\n",
    "\n",
    "Here's a simplified approach:\n",
    "\n",
    "Extract Activations: Modify the model to return the activations from the last convolutional layer in addition\n",
    "to the final output.\n",
    "Average Activations: Compute the average of these activations across all channels to get a single 1D array\n",
    "representing the importance of each time step.\n",
    "Normalize: Normalize this array to have values between 0 and 1.\n",
    "Visualize: Plot these normalized values as a heatmap alongside the original time series data.\n",
    "Here's how you can modify your TimeSeriesCNN class and add a simple heatmap visualization:\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TimeSeriesCNN(nn.Module):\n",
    "    def __init__(self, args, device, sequence_length):\n",
    "        super(TimeSeriesCNN, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        self.sequence_length = sequence_length\n",
    "        self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=5, out_channels=256, kernel_size=32),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=8)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=256, out_channels=64, kernel_size=4),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=int((self.sequence_length - 32)/8 - 4 + 1))\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        activations = x\n",
    "        x = x.view(-1, 64)  # Flatten the tensor\n",
    "        x = self.mlp(x)\n",
    "        return F.log_softmax(x, dim=1), activations\n",
    "\n",
    "def visualize_simple_heatmap(original_time_series, activations):\n",
    "    # Assuming activations is a tensor of shape (batch_size, num_channels, length)\n",
    "    # Compute the average across channels\n",
    "    heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "    heatmap = heatmap.cpu().detach().numpy()\n",
    "    heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap))  # Normalize\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(original_time_series[:, 0], label='Original Time Series')\n",
    "    plt.imshow(np.array([heatmap for _ in range(original_time_series.shape[1])]).T, cmap='hot', aspect='auto', alpha=0.5)\n",
    "    plt.colorbar(label='Activation Intensity')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# model = TimeSeriesCNN(args, device, sequence_length)\n",
    "# output, activations = model(input_data)\n",
    "# visualize_simple_heatmap(original_time_series, activations)\n",
    "\n",
    "'''\n",
    "This approach provides a straightforward way to visualize which parts of the input time series are activating the neurons\n",
    "in the last convolutional layer the most, giving you a rough idea of what the model is paying attention to. Remember, this\n",
    "method averages across all channels and thus might lose some specificity in what different channels might be focusing on.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386c11c-1342-4a3f-94ef-a1f153550a81",
   "metadata": {},
   "source": [
    "### Parallel CNN-DT Model\n",
    "\n",
    "**Input for CNN:** Wavelet transformed data not subjected to manual feature extraction.\n",
    "\n",
    "**Input for DT:** Four features extracted from recordings - variance of acoustic emissions, energy of acoustic emissions, variance of current, energy of current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3540835-776c-4d9a-a6b0-868569fa290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Train CNN\n",
    "# - Train the CNN model on the original dataset.\n",
    "# - Implement training loop, loss function, optimizer, etc., for the CNN.\n",
    "\n",
    "# Step 2: Feature Extraction with CNN\n",
    "# - Use the trained CNN model to extract features from the dataset.\n",
    "# - This involves passing the dataset through the CNN and using the output of the last convolutional layer as features.\n",
    "\n",
    "# Step 3: Train DT\n",
    "# - Use the extracted features from Step 2 as input to train the Decision Tree classifier.\n",
    "# - Implement the training process for the DT using the extracted features and corresponding labels.\n",
    "\n",
    "# Step 4: Combine Predictions\n",
    "# - For making predictions, input the data through both models to get their predictions.\n",
    "# - Combine these predictions using a weighted scheme to make a final decision.\n",
    "# - The weights can be determined based on validation performance or set empirically.\n",
    "\n",
    "# Implementation in Python\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class MixedModel:\n",
    "    def __init__(self, cnn_model, dt_model, cnn_weight=0.5):\n",
    "        self.cnn_model = cnn_model\n",
    "        self.dt_model = dt_model\n",
    "        self.cnn_weight = cnn_weight\n",
    "\n",
    "    def train_cnn(self, train_loader, epochs=10):\n",
    "        # Implement CNN training here\n",
    "        pass\n",
    "\n",
    "    def extract_features(self, data_loader):\n",
    "        # Implement feature extraction using CNN here\n",
    "        pass\n",
    "\n",
    "    def train_dt(self, features, labels):\n",
    "        # Implement DT training here\n",
    "        pass\n",
    "\n",
    "    def predict(self, data_loader):\n",
    "        # Implement prediction method that combines CNN and DT predictions\n",
    "        pass\n",
    "\n",
    "# Assuming TimeSeriesCNN and TimeSeriesDT are defined as provided\n",
    "# Initialize CNN and DT\n",
    "cnn_model = TimeSeriesCNN(args, device, sequence_length)\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Create MixedModel instance\n",
    "mixed_model = MixedModel(cnn_model, dt_model)\n",
    "\n",
    "# Train CNN\n",
    "# mixed_model.train_cnn(train_loader)\n",
    "\n",
    "# Extract features using CNN\n",
    "# features, labels = mixed_model.extract_features(data_loader)\n",
    "\n",
    "# Train DT with extracted features\n",
    "# mixed_model.train_dt(features, labels)\n",
    "\n",
    "# Make predictions with the mixed model\n",
    "# predictions = mixed_model.predict(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea76c49f-5198-49f5-ad83-0aa40120148a",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "No need to edit this one, but comments welcome\n",
    "\n",
    "**Input:** Four features extracted from recordings - variance of acoustic emissions, energy of acoustic emissions, variance of current, energy of current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b854f-aecf-40f6-aee3-8e88681b43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Sample dataset\n",
    "dataset = [\n",
    "    (0.0028296275479566097, 0.014225336147977692, 106988.68985835543, 111653.46909800009, 'anomalous', 'grinding'),\n",
    "    # Add the rest of your dataset here\n",
    "]\n",
    "\n",
    "# Extract features and labels\n",
    "features = np.array([datapoint[:4] for datapoint in dataset])\n",
    "labels_anomalous = np.array([datapoint[4] for datapoint in dataset])\n",
    "labels_process = np.array([datapoint[5] for datapoint in dataset])\n",
    "\n",
    "# Encode categorical labels\n",
    "encoder_anomalous = LabelEncoder()\n",
    "encoder_process = LabelEncoder()\n",
    "labels_anomalous_encoded = encoder_anomalous.fit_transform(labels_anomalous)\n",
    "labels_process_encoded = encoder_process.fit_transform(labels_process)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train_anomalous, X_val_anomalous, y_train_anomalous, y_val_anomalous = train_test_split(features, labels_anomalous_encoded, test_size=0.2, random_state=42)\n",
    "X_train_process, X_val_process, y_train_process, y_val_process = train_test_split(features, labels_process_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression models\n",
    "model_anomalous = LogisticRegression(max_iter=1000)\n",
    "model_anomalous.fit(X_train_anomalous, y_train_anomalous)\n",
    "\n",
    "model_process = LogisticRegression(max_iter=1000)\n",
    "model_process.fit(X_train_process, y_train_process)\n",
    "\n",
    "# Evaluate the models\n",
    "y_pred_anomalous = model_anomalous.predict(X_val_anomalous)\n",
    "y_pred_process = model_process.predict(X_val_process)\n",
    "\n",
    "print(\"Accuracy for 'anomalous'/'normal':\", accuracy_score(y_val_anomalous, y_pred_anomalous))\n",
    "print(\"Accuracy for 'dressing'/'grinding':\", accuracy_score(y_val_process, y_pred_process))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
